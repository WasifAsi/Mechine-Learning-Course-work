{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (36168, 42)\n",
      "X_test shape: (9043, 42)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset (replace 'your_dataset.csv' with the actual dataset file)\n",
    "data = pd.read_csv('preprocessed_data.csv')\n",
    "\n",
    "# Assuming the last column is the target variable (y), and the rest are features (X)\n",
    "X = data.drop('y', axis=1)  # Assuming 'y' is your target column\n",
    "y = data['y']\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Example: Check the shape of the datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the saved model\n",
    "rf_model = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy :.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Load the saved TensorFlow model\n",
    "# tensorflow_model = tf.keras.models.load_model('best_tuned_mode_Ten.h5')\n",
    "\n",
    "# # Predict on the test set\n",
    "# tensorflow_predictions = tensorflow_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "# # Calculate accuracy\n",
    "# tensorflow_accuracy = accuracy_score(y_test, tensorflow_predictions)\n",
    "# print(f\"TensorFlow NN Accuracy: {tensorflow_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight: torch.Size([32, 42])\n",
      "fc1.bias: torch.Size([32])\n",
      "fc2.weight: torch.Size([2, 32])\n",
      "fc2.bias: torch.Size([2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wasif\\AppData\\Local\\Temp\\ipykernel_19656\\2204771781.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"best_NN_model.pth\", map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the saved model state dict\n",
    "model = torch.load(\"best_NN_model.pth\", map_location='cpu')\n",
    "\n",
    "# Check the layers in the model state dict\n",
    "for name, param in model.items():\n",
    "    print(f\"{name}: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wasif\\AppData\\Local\\Temp\\ipykernel_19656\\3095676625.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9074\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      7952\n",
      "           1       0.66      0.49      0.56      1091\n",
      "\n",
      "    accuracy                           0.91      9043\n",
      "   macro avg       0.79      0.73      0.75      9043\n",
      "weighted avg       0.90      0.91      0.90      9043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Define the model class (same as used during training)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to load the model\n",
    "def load_model(model_path, input_size, hidden_size, output_size, device):\n",
    "    model = NeuralNet(input_size=input_size, hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Function to evaluate the model on a dataset (accuracy and classification report)\n",
    "def evaluate_model_on_dataset(model, X_test, y_test, batch_size, device):\n",
    "    # Convert the test dataset into a DataLoader\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test.values, dtype=torch.float32), \n",
    "                                  torch.tensor(y_test.values, dtype=torch.long))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    y_pred, y_true = [], []\n",
    "    with torch.no_grad():  # No gradients needed for evaluation\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move to GPU if available\n",
    "            outputs = model(X_batch)  # Get model predictions\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the predicted class index\n",
    "            y_pred.extend(predicted.cpu().numpy())  # Move predictions to CPU\n",
    "            y_true.extend(y_batch.cpu().numpy())  # Move true labels to CPU\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Print accuracy\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Print classification report (precision, recall, F1 score)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Load your test dataset (X_test, y_test)\n",
    "# Assuming X_test and y_test are pandas DataFrames or NumPy arrays\n",
    "# For example:\n",
    "# X_test = pd.read_csv(\"X_test.csv\")  # or use the dataset you have\n",
    "# y_test = pd.read_csv(\"y_test.csv\")  # or use the dataset you have\n",
    "\n",
    "# Define your model's input, hidden, and output sizes\n",
    "input_size = X_test.shape[1]  # Assuming X_test is a DataFrame\n",
    "hidden_size = 32  # You can change this to the value used during training\n",
    "output_size = 2  # Assuming binary classification\n",
    "\n",
    "# Path to the saved model\n",
    "model_path = \"best_NN_model.pth\"\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = load_model(model_path, input_size, hidden_size, output_size, device)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "batch_size = 32  # Adjust the batch size based on your memory\n",
    "evaluate_model_on_dataset(model, X_test, y_test, batch_size, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
